here
None
Filename: memory_profiling_test.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    51   44.297 MiB   44.297 MiB           1   @profile
    52                                         def adv_fun():
    53   44.297 MiB    0.000 MiB           1       import os
    54   45.531 MiB    1.234 MiB           1       from PIL import Image
    55                                             #from proper_utils import get_inference_result, get_adversarial_result
    56   45.625 MiB    0.094 MiB           1       from memory_profiler import profile
    57                                             #import torch
    58  199.422 MiB  153.797 MiB           1       import torch
    59  212.734 MiB   13.312 MiB           1       from torchvision import transforms
    60  212.734 MiB    0.000 MiB           1       import torchvision.models as models
    61  212.734 MiB    0.000 MiB           1       from PIL import Image
    62  212.734 MiB    0.000 MiB           1       from PIL import ImageDraw, ImageFont
    63  212.734 MiB    0.000 MiB           1       import torch.nn.functional as F
    64  212.734 MiB    0.000 MiB           1       import numpy as np
    65  212.734 MiB    0.000 MiB           1       import warnings
    66                                             # Convert the uploaded image to an PIL.Image.Image
    67  212.734 MiB    0.000 MiB           1       filename = '/Users/hrushi/Desktop/dove.jpg'
    68  221.422 MiB    8.688 MiB           1       with Image.open(filename) as input_image:
    69  228.297 MiB    6.875 MiB           1          input_image.load()
    70  228.312 MiB    0.016 MiB           1       input_image = input_image.convert('RGB')
    71                                             # Let's have a standard image size to avoid resizing with html
    72  230.016 MiB    1.703 MiB           1       input_image = input_image.resize((512, 512))
    73  230.219 MiB    0.203 MiB           1       input_image.save('delete_later.png')
    74                                         
    75                                             # Perform inference using the get_inference_result function
    76  230.219 MiB    0.000 MiB           1       if input_image.mode == 'RGBA':
    77                                                 input_image = input_image.convert('RGB')
    78                                         
    79  230.219 MiB    0.000 MiB           1       model_path = 'model/squeezenet_model.pth'
    80                                             # model = models.squeezenet1_1(pretrained=False)
    81  234.391 MiB    4.172 MiB           1       model = models.squeezenet1_1(weights=None)
    82  234.984 MiB    0.594 MiB           1       state_dict = torch.load(model_path)
    83  235.312 MiB    0.328 MiB           1       model.load_state_dict(state_dict)
    84  235.312 MiB    0.000 MiB           1       model.eval()
    85                                         
    86  235.312 MiB    0.000 MiB           2       preprocess = transforms.Compose([
    87  235.312 MiB    0.000 MiB           1           transforms.Resize(256),
    88  235.312 MiB    0.000 MiB           1           transforms.CenterCrop(224),
    89  235.312 MiB    0.000 MiB           1           transforms.ToTensor(),
    90  235.312 MiB    0.000 MiB           1           transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    91                                             ])
    92  238.234 MiB    2.922 MiB           1       input_tensor = preprocess(input_image)
    93                                             # create a mini-batch as expected by the model
    94  238.250 MiB    0.016 MiB           1       input_batch = input_tensor.unsqueeze(0)  
    95  238.250 MiB    0.000 MiB           1       input_batch.requires_grad = True
    96  238.250 MiB    0.000 MiB           1       with torch.enable_grad():
    97  257.328 MiB   19.078 MiB           1           output = model(input_batch)
    98                                         
    99                                             # Tensor of shape 1000, with confidence scores over Imagenet's 1000 classes
   100  257.484 MiB    0.156 MiB           1       probabilities = torch.nn.functional.softmax(output[0], dim=0) 
   101  257.484 MiB    0.000 MiB           1       with open("imagenet_classes.txt", "r") as f:
   102  257.609 MiB    0.125 MiB        1003           categories = [s.strip() for s in f.readlines()]
   103                                         
   104  257.734 MiB    0.125 MiB           1       top5_prob, top5_catid = torch.topk(probabilities, 5)
   105  257.734 MiB    0.000 MiB           1       result = []
   106  257.766 MiB    0.000 MiB           6       for i in range(top5_prob.size(0)):
   107  257.766 MiB    0.031 MiB           5           result.append((i+1, categories[top5_catid[i]], round(top5_prob[i].item() * 100, 2)))
   108                                         
   109                                             # Get the predicted class
   110  257.906 MiB    0.141 MiB           1       _, predicted_class = torch.max(output, 1)
   111                                         
   112  258.094 MiB    0.188 MiB           1       loss = torch.nn.functional.nll_loss(output, predicted_class)
   113  258.094 MiB    0.000 MiB           1       model.zero_grad()
   114  278.562 MiB   20.469 MiB           1       loss.backward()
   115                                         
   116                                             # Collect the gradients of the input image
   117  278.562 MiB    0.000 MiB           1       data_grad = input_batch.grad.data
   118                                         
   119                                             # Using a very high epsilon value so change is evident
   120  278.562 MiB    0.000 MiB           1       epsilon=24/255
   121                                             # Create the adversarial image by perturbing the input image
   122  278.703 MiB    0.141 MiB           1       perturbation = epsilon * torch.sign(data_grad)
   123  278.734 MiB    0.031 MiB           1       perturbed_image = input_batch + perturbation
   124                                         
   125                                             # Clamp the pixel values to the valid range [0, 1]
   126  278.797 MiB    0.062 MiB           1       perturbed_image = torch.clamp(perturbed_image, 0, 1)
   127                                         
   128  278.797 MiB    0.000 MiB           1       with torch.no_grad():
   129  281.891 MiB    3.094 MiB           1           adversarial_output = model(perturbed_image)
   130                                         
   131  281.891 MiB    0.000 MiB           1       adversarial_probabilities = torch.nn.functional.softmax(adversarial_output[0], dim=0)
   132                                         
   133  281.906 MiB    0.016 MiB           1       top5_prob, top5_catid = torch.topk(adversarial_probabilities, 5)
   134  281.906 MiB    0.000 MiB           1       original_result = []
   135  281.906 MiB    0.000 MiB           6       for i in range(top5_prob.size(0)):
   136  281.906 MiB    0.000 MiB           5           original_result.append((i+1, categories[top5_catid[i]], round(top5_prob[i].item() * 100, 2)))
   137                                             
   138                                             # Get the class labels from the original result
   139  281.906 MiB    0.000 MiB           8       original_classes = [item[1] for item in original_result]
   140                                         
   141                                             # Find the indices of original classes in the adversarial probabilities
   142  281.906 MiB    0.000 MiB           8       original_indices = [categories.index(cls) for cls in original_classes]
   143                                         
   144                                             # Extract the probabilities of original classes from the adversarial probabilities
   145  281.906 MiB    0.000 MiB           1       adversarial_top5_class_probabilities = []
   146  281.906 MiB    0.000 MiB           6       for i, index in enumerate(original_indices):
   147  281.906 MiB    0.000 MiB           5           probability = adversarial_probabilities[index]
   148  281.906 MiB    0.000 MiB           5           class_name = original_result[i][1]
   149  281.906 MiB    0.000 MiB           5           adversarial_top5_class_probabilities.append((i + 1, class_name, round(probability.item() * 100, 1)))
   150                                         
   151                                             
   152  282.016 MiB    0.109 MiB           1       perturbation = perturbation.squeeze().permute(1, 2, 0).detach().numpy()
   153  282.781 MiB    0.766 MiB           1       multipled_perturbation = Image.fromarray((perturbation * 255 * 50).astype(np.uint8), mode='RGB')
   154  282.781 MiB    0.000 MiB           1       multipled_perturbation = multipled_perturbation.resize((512, 512))
   155  282.781 MiB    0.000 MiB           1       normal_perturbation = Image.fromarray((perturbation * 255).astype(np.uint8), mode='RGB')
   156                                         
   157  282.797 MiB    0.016 MiB           1       resized_perturbation = normal_perturbation.resize(input_image.size)
   158                                         
   159                                             # We can directly add using Pillow
   160                                             
   161                                             #resized_perturbation_rgb = resized_perturbation.convert("RGB")
   162                                             #input_image_rgb = input_image.convert("RGB")
   163                                             #adversarial_image = Image.blend(resized_perturbation_rgb, input_image_rgb, alpha=0.5)
   164                                         
   165                                             # OR WE CAN CONVERT TO NUMPY TO GET BETTER ADDITION
   166                                             # Convert images to NumPy arrays and perform addition of the two arrays
   167  285.828 MiB    3.031 MiB           1       adversarial_image_array = np.array(resized_perturbation).astype(np.uint16) + np.array(input_image).astype(np.uint16)
   168                                             # Ensure the resulting array is within the valid range [0, 255]
   169  285.844 MiB    0.016 MiB           1       adversarial_image_array = np.clip(adversarial_image_array, 0, 255)
   170                                             # Convert the adversarial_image_array  back to PIL.Image.Image
   171  285.859 MiB    0.016 MiB           1       adversarial_image = Image.fromarray(adversarial_image_array.astype(np.uint8))
   172                                         
   173                                             # Create a new blank image with the stacked dimensions
   174  285.859 MiB    0.000 MiB           1       stacked_width = input_image.width + adversarial_image.width + 1  # Add 1 pixel for the boundary
   175  285.859 MiB    0.000 MiB           1       stacked_height = max(input_image.height, adversarial_image.height)
   176  285.859 MiB    0.000 MiB           1       stacked_image = Image.new('RGB', (stacked_width, stacked_height))
   177                                         
   178                                             # Paste the input_image on the left and adversarial_image on the right
   179  285.859 MiB    0.000 MiB           1       stacked_image.paste(input_image, (0, 0))
   180  285.859 MiB    0.000 MiB           1       stacked_image.paste(adversarial_image, (input_image.width + 1, 0))  # Add 1 pixel offset for the boundary
   181                                         
   182                                             # Add a boundary line
   183  285.859 MiB    0.000 MiB           1       boundary_color = (255, 0, 0)  # Red color for the boundary line
   184  285.859 MiB    0.000 MiB           1       boundary_width = 2  # Width of the boundary line
   185  285.859 MiB    0.000 MiB           1       line_coordinates = [(input_image.width, 0), (input_image.width, stacked_height - 1)]  # Coordinates for the line
   186  285.859 MiB    0.000 MiB           1       line_draw = ImageDraw.Draw(stacked_image)
   187  285.859 MiB    0.000 MiB           1       line_draw.line(line_coordinates, fill=boundary_color, width=boundary_width)
   188                                         
   189                                             # Add labels to the images
   190  286.062 MiB    0.203 MiB           1       label_font = ImageFont.truetype("Arial.ttf", size=24)  # Set the font and size for the labels
   191  286.062 MiB    0.000 MiB           1       label_draw = ImageDraw.Draw(stacked_image)
   192                                         
   193                                             # Add label for the original image
   194  286.141 MiB    0.078 MiB           1       label_draw.text((10, 10), "Original", fill=(112, 238, 27, 1), font=label_font)
   195                                         
   196                                             # Add label for the adversarial image
   197  286.141 MiB    0.000 MiB           1       label_draw.text((input_image.width + 10, 10), "Adversarial", fill="red", font=label_font)
   198                                         
   199                                             # Save the stacked image
   200  286.141 MiB    0.000 MiB           1       stacked_save_path = f'del1.png'
   201  286.156 MiB    0.016 MiB           1       stacked_image.save(stacked_save_path)
   202                                         
   203                                             # Save the perturbation scaled by 50
   204  286.156 MiB    0.000 MiB           1       scaled_save_path = f'del2.png'
   205  286.156 MiB    0.000 MiB           1       multipled_perturbation.save(scaled_save_path)
   206                                         
   207                                             # Save the perturbed input image
   208  286.156 MiB    0.000 MiB           1       adversarial_image_path = f'del3.png'
   209  286.156 MiB    0.000 MiB           1       adversarial_image.save(adversarial_image_path)    


